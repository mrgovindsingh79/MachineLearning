{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rt\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    #print(separated)\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def mean(numbers):\n",
    "    numbers = np.array(numbers)\n",
    "    \n",
    "    f1 = numbers[:,0].astype(float)\n",
    "    f2 = numbers[:,1].astype(float)\n",
    "    #print(f1)\n",
    "    #print(f2)\n",
    "    xx = np.mean(f1)\n",
    "    yy = np.mean(f2)\n",
    "    \n",
    "    cov = np.cov(f1,f2)\n",
    "    mean = (xx,yy)\n",
    "    m = list(mean)\n",
    "    \n",
    "    return m,cov\n",
    "    \n",
    "#def cov(numbers):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    #for x in range(3):\n",
    "    #print(dataset,'dssd',len(dataset))\n",
    "    #summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    summaries = []\n",
    "    #print(dataset,'hye')\n",
    "    m = mean(dataset)\n",
    "    #cv = covm(dataset)\n",
    "    summaries.append(m)\n",
    "    #summaries.append(cv)\n",
    "    \n",
    "    #del summaries[-1]\n",
    "    #print(summaries)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    #print(separated)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    #print(summaries)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "def calculateProbability(x, mean, cov):\n",
    "    #pp = np.array(x) - np.array(mean)\n",
    "    \n",
    "    #determinant of covariance matrix\n",
    "    det_cov = np.linalg.det(cov)\n",
    "    pp = list(map(operator.sub,x,mean)) \n",
    "    #print(x,mean)\n",
    "    #print('covariance',cov)\n",
    "    #print('x-mean',pp)\n",
    "    \n",
    "    \n",
    "    #inverse of the covariance matrix\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    \n",
    "    pt = np.array(pp).reshape(2,1)\n",
    "    parta = np.dot(pp,inv_cov)\n",
    "    partb = np.dot(parta,pt)\n",
    "    part1 = math.exp(-1/2 * partb)\n",
    "    #print(part1)\n",
    "    \n",
    "    part2 = 2 * math.pi * math.sqrt(det_cov)\n",
    "    #print('part2',part2)\n",
    "    \n",
    "    gauss = part1/part2\n",
    "    \n",
    "    #print('transpose',pt)\n",
    "    #inv_cov = np.linalg.det(cov)\n",
    "    #print(gauss)\n",
    "    #print(parta)\n",
    "    #print\n",
    "    \n",
    "    return gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    del inputVector [-1]\n",
    "    #print(inputVector)\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, cov = classSummaries[i]\n",
    "            #x = inputVector.loc[i][1,2]\n",
    "            #print(cov)\n",
    "            probabilities[classValue] *= calculateProbability(inputVector, mean, cov)\n",
    "            #print(probabilities)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(summaries, inputVector):\n",
    "    #print(inputVector)\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(parameters, testSet):\n",
    "    #print(testSet)\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(parameters, testSet[i])\n",
    "        predictions.append(result)\n",
    "    #print('pp',predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    #test = np.array(testSet)\n",
    "    #test = testSet[-1]\n",
    "    #print(testSet)\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x] == predictions[x]:\n",
    "            correct += 1\n",
    "            #print(testSet[x][-1])\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of trainingSet is  201 and testing size is  99\n",
      "Accuracy: 38.38383838383838\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.12      0.03      0.04        37\n",
      "        2.0       0.39      0.88      0.54        32\n",
      "        3.0       0.47      0.30      0.37        30\n",
      "\n",
      "avg / total       0.32      0.38      0.30        99\n",
      "\n",
      "         class-1  class-2  class-3\n",
      "class-1        1       29        7\n",
      "class-2        1       28        3\n",
      "class-3        6       15        9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from pandas import * \n",
    "def main():\n",
    "    filename = r'C:\\Users\\Govind\\Downloads\\02-Govind\\group02\\dataset\\2d_image_all.csv'\n",
    "    splitRatio = 0.67\n",
    "    dataset = loadCsv(filename)\n",
    "    trainingSet,testSet = splitDataset(dataset, splitRatio)\n",
    "    print('Size of trainingSet is ',len(trainingSet),'and testing size is ',len(testSet))\n",
    "    #print(testSet)\n",
    "    test = []\n",
    "    for x in range (len(testSet)):\n",
    "        a = testSet[x][-1]\n",
    "        test.append(a)\n",
    "    \n",
    "    parameters = summarizeByClass(trainingSet)\n",
    "    #print(parameters)\n",
    "    #print(testSet)\n",
    "    \n",
    "    predictions = getPredictions(parameters, testSet)\n",
    "    #print(test)\n",
    "    accuracy = getAccuracy(test, predictions)\n",
    "    #for x in range (len(test)):\n",
    "        #print('> predicted=' + repr(predictions) + ', actual=' + repr(testSet[x]))\n",
    "    \n",
    "    print('Accuracy:',accuracy)\n",
    "    print(classification_report(test, predictions))\n",
    "    results = confusion_matrix(test, predictions)\n",
    "    print(DataFrame(results, columns=[\"class-1\", \"class-2\", \"class-3\"], index=[\"class-1\", \"class-2\", \"class-3\"]))\n",
    "    #print(results)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
